[project]
name = "my-sujbot"
version = "0.1.0"
description = "Document extraction and analysis bot with hierarchical structure support"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    # Core dependencies
    "python-dotenv>=1.0.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    # PDF Processing
    "pypdf2>=3.0.0",
    "pymupdf>=1.23.0", # Advanced PDF processing (duplicate detection, text extraction)
    # Unstructured.io - Multi-format document extraction (PDF, DOCX, PPTX, HTML, TXT, LaTeX)
    "unstructured[all-docs]>=0.10.0", # All format support (including detectron2 for PDF)
    # IBM Docling - Advanced document structure extraction
    "docling>=2.57.0",
    "docling-core>=2.48.0",
    "docling-parse>=4.4.0",
    "docling-ibm-models>=3.9.0",
    # Docling dependencies
    "pypdfium2>=4.30.0",
    "filetype>=1.2.0",
    "rtree>=1.3.0",
    "python-docx>=1.1.2",
    "python-pptx>=1.0.2",
    "openpyxl>=3.1.5",
    "beautifulsoup4>=4.12.3",
    "pandas>=2.1.4",
    "lxml>=4.0.0",
    "pillow>=10.0.0",
    "pylatexenc>=2.10",
    "scipy>=1.6.0",
    "marko>=2.1.2",
    # ML/AI for Docling
    # NOTE: PyTorch requires platform-specific installation
    # See INSTALL.md for platform-specific instructions
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    "transformers>=4.34.0",
    "accelerate>=1.0.0",
    "safetensors>=0.4.3",
    # OCR support (cross-platform)
    "rapidocr>=3.3.0",
    "opencv-python>=4.5.1",
    # LLM & Text Processing
    "anthropic>=0.18.0",
    "openai>=2.0.0",
    "google-generativeai>=0.8.0", # Google Gemini models (unified - replaces google-genai)
    "google-api-core>=2.0.0", # Required for Gemini exception handling
    "langchain-text-splitters>=0.0.1",
    "langgraph>=0.2.0", # Multi-agent orchestration framework
    "langgraph-checkpoint-postgres>=2.0.0", # PostgreSQL checkpointing
    "langsmith>=0.4.0", # LangSmith observability
    "openevals>=0.1.0", # LLM-as-judge evaluators for LangSmith
    # LlamaIndex - Ingestion pipeline with state management
    "llama-index-core>=0.12.0", # Core abstractions (IngestionPipeline, TransformComponent)
    "llama-index-storage-kvstore-redis>=0.3.0", # Redis cache for state persistence
    "redis>=5.0.0", # Redis client for direct cache operations
    "tiktoken>=0.5.0", # Token counting for smart truncation
    "sentence-transformers>=5.1.2", # Reranker + local embedding features
    # Vector Store
    "faiss-cpu>=1.7.4",
    "rank-bm25>=0.2.2", # PHASE 5B: Hybrid search (BM25 sparse retrieval)
    "numpy>=1.24.0",
    # Clustering (PHASE 4.5: Semantic clustering)
    "scikit-learn>=1.3.0", # Agglomerative clustering, metrics
    "hdbscan>=0.8.33", # HDBSCAN clustering with cosine distance
    "umap-learn>=0.5.5", # UMAP dimensionality reduction for visualization
    "matplotlib>=3.5.0", # Plotting for cluster visualization
    # Knowledge Graph (Neo4j backend + Graphiti)
    "neo4j>=5.25.0", # Neo4j Python driver for graph database
    "networkx>=3.0", # Graph algorithms and analysis
    "graphiti-core==0.24.1", # Graphiti temporal KG with GPT-4o-mini extraction
    # CLI & Utilities
    "click>=8.1.0",
    "tqdm>=4.65.0",
    "asyncpg>=0.30.0",
    "psycopg[binary]>=3.1.0",  # PostgreSQL adapter with binary wheels
    "nest-asyncio>=1.6.0",
    # Authentication & Security
    "argon2-cffi>=23.1.0",  # Argon2 password hashing
    "PyJWT>=2.8.0",  # JWT token generation/validation
    "pdf2image>=1.17.0",
    "json-repair>=0.54.1",
    "pyvis>=0.3.2",
    "langchain-anthropic>=1.0.4",
]

[project.optional-dependencies]
# Development tools
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.12.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "mypy>=1.7.0",
]

# Local embeddings (BGE-M3, requires PyTorch)
local-embeddings = [
    "sentence-transformers>=2.2.0",
]

# Voyage AI embeddings (cloud-based, recommended)
voyage = [
    "voyageai>=0.2.0",
]

# Knowledge Graph support
knowledge-graph = [
    "networkx>=3.0",
    "neo4j>=5.25.0",
    "pyvis>=0.3.0",  # Interactive graph visualization
]

# Language processing for BM25 hybrid search (PHASE 5B)
language-support = [
    "spacy>=3.7.0",  # Lemmatization + stop words (best quality)
    "langdetect>=1.0.9",  # Auto language detection
    "nltk>=3.8.0",  # Stop words fallback
]

# All optional features
all = [
    "sentence-transformers>=2.2.0",
    "voyageai>=0.2.0",
    "networkx>=3.0",
    "neo4j>=5.0.0",
    "spacy>=3.7.0",
    "langdetect>=1.0.9",
    "nltk>=3.8.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

[dependency-groups]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.12.0",
    "black>=23.0.0",
    "isort>=5.12.0",
    "mypy>=1.7.0",
    "docx>=0.2.4",
    "pytesseract>=0.3.13",
    "fitz>=0.0.1.dev2",
]

[tool.black]
line-length = 100
target-version = ["py310"]

[tool.isort]
profile = "black"
line_length = 100

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false

[tool.pytest.ini_options]
# Test discovery
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

# Exclude manual tests (require optional dependencies like neo4j)
# and deprecated test files with import errors
norecursedirs = ["tests/manual", "tests/old", "tests/deprecated", ".git", "node_modules"]
addopts = [
    "--ignore=tests/test_docling_extraction.py",
    "--ignore=tests/test_pipeline.py",
    "--ignore=tests/test_benchmark_report.py",
    "--ignore=tests/manual"
]
