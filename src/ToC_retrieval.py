"""
ToC Retrieval Pipeline - LLM-based Table of Contents Extraction

This module provides an ALTERNATIVE extraction method for documents where:
1. PDF embedded outline/bookmarks are missing (Tier 1)
2. Visual ToC pages exist but aren't in metadata (Tier 2)

WHEN TO USE:
- Use this for documents where unstructured_extractor.py fails to extract structure
- Cost: ~$0.003 per document (Gemini 2.5 Flash)
- Supports: PDF (with potential for .tex, .txt extension)

INTEGRATION POINT:
- This is NOT part of the main indexing pipeline (run_pipeline.py)
- Use as a pre-processing step or fallback for structure extraction
- Output HierarchyNode can be converted to DoclingDocument format

STATUS CODES:
- "TIER_1_SUCCESS": PDF has embedded outline/bookmarks
- "TIER_2_SUCCESS": TOC found via LLM heuristic analysis
- "TIER_2_FAILURE": Heuristic failed to find TOC header
- "ERROR_DOC_OPEN": Failed to open PDF document
- "ERROR_AGENT_INIT": LLM agent initialization failed
"""

# ==============================================================================
# 0. IMPORTS AND HELPERS
# ==============================================================================
import os
import re
import json
import logging
from abc import ABC, abstractmethod
from typing import List, Tuple, Optional, Dict, Any, Type
from dotenv import load_dotenv

import fitz
import google.generativeai as genai
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)






# ==============================================================================
# 1. T≈ò√çDY DAT A ARCHITEKTURY
# ==============================================================================

HeadingData = Tuple[str, int, int] # (title, level, page_number)

# --- Abstraktn√≠ T≈ô√≠da (Kontrakt) ---
class BaseDocumentParser(ABC):
    def __init__(self, file_path: str):
        self.file_path: str = file_path
        
    @abstractmethod
    def get_document_type(self) -> str:
        pass

    # V≈°imnƒõte si, ≈æe vrac√≠me TROJICI: (List nadpis≈Ø, Surov√Ω OCR text, celkov√°_cena)
    @abstractmethod
    def extract_structured_headings(self) -> Tuple[List[HeadingData], Optional[str], float]:
        pass

class HierarchyNode:
    """Reprezentuje jeden uzel v hierarchick√© stromov√© struktu≈ôe."""
    def __init__(self, title: str, level: int, page_number: Optional[int] = None):
        self.title: str = title
        self.level: int = level 
        self.page_number: Optional[int] = page_number
        self.children: List['HierarchyNode'] = []

    def add_child(self, child_node: 'HierarchyNode'):
        self.children.append(child_node)

    def __repr__(self) -> str:
        return f"Node(title='{self.title[:30]}...', level={self.level}, page={self.page_number}, children={len(self.children)})"


class HierarchyBuilder:
    """Sestavuje hierarchick√Ω strom z ploch√©ho seznamu nadpis≈Ø pomoc√≠ z√°sobn√≠ku."""
    
    def __init__(self):
        self.ROOT_TITLE = "Document Root"
        self.ROOT_LEVEL = 0
        self.ROOT_PAGE = 1
        
    def build_tree(self, headings: List[HeadingData]) -> Optional['HierarchyNode']:
        """Konstruuje strom."""
        if not headings:
            return None

        root = HierarchyNode(self.ROOT_TITLE, self.ROOT_LEVEL, self.ROOT_PAGE)
        # Z√°sobn√≠k dr≈æ√≠ (√∫rove≈à, uzel)
        node_stack: List[Tuple[int, 'HierarchyNode']] = [(self.ROOT_LEVEL, root)]

        for title, level, page_num in headings:
            new_node = HierarchyNode(title, level, page_num)
            
            # Pop z≈ôetƒõzen√≠ dokud nenajdeme spr√°vn√©ho rodiƒçe
            while node_stack and level <= node_stack[-1][0]:
                node_stack.pop()
            
            if node_stack:
                node_stack[-1][1].add_child(new_node)
                node_stack.append((level, new_node))

        return root

# --- Manu√°ln√≠ Definice Sch√©mat pro Gemini API ---

# Sch√©ma pro F√°zi 1 (Hled√°n√≠ prvn√≠ kapitoly)
FIRST_CHAPTER_SCHEMA_DICT = {
    "type": "object",
    "properties": {
        "first_chapter_page": {
            "type": "integer",
            "description": "ƒå√≠slo str√°nky (1-based), kde zaƒç√≠n√° prvn√≠ hlavn√≠ kapitola/sekce (nap≈ô. '1. √övod' nebo 'Kapitola I')."
        }
    },
    "required": ["first_chapter_page"]
}

# Sch√©ma pro F√°zi 2 (Kompletn√≠ struktura)
# V≈°imnƒõte si, jak je 'HeadingItem' definov√°n p≈ô√≠mo uvnit≈ô 'items'
FULL_STRUCTURE_SCHEMA_DICT = {
    "type": "object",
    "properties": {
        "headings": {
            "type": "array",
            "description": "Kompletn√≠ seznam v≈°ech hierarchick√Ωch polo≈æek z obsahu.",
            "items": {
                "type": "object",
                "properties": {
                    "title": {
                        "type": "string",
                        "description": "ƒåist√Ω n√°zev kapitoly nebo sekce."
                    },
                    "level": {
                        "type": "integer",
                        "description": "Odvozen√° hierarchick√° √∫rove≈à (1 pro nejvy≈°≈°√≠, 2 pro podsekci atd.)."
                    },
                    "page_number": {
                        "type": "integer",
                        "description": "ƒå√≠slo str√°nky, kde tato sekce zaƒç√≠n√°."
                    }
                },
                "required": ["title", "level", "page_number"]
            }
        }
    },
    "required": ["headings"]
}

class LLMAgent:
    """
    Zapouzd≈ôuje vol√°n√≠ LLM a nyn√≠ tak√© sleduje n√°klady na tokeny.

    NOTE: Pricing accurate as of 2025-01. Update according to https://ai.google.dev/pricing
    """

    MODEL_PRICING = {
        "models/gemini-2.5-flash": {
            "input": 0.30,  # USD per 1M tokens
            "output": 0.60
        },
        "default": {
            "input": 0.50,
            "output": 1.50
        }
    }

    def __init__(self):
        # Load API key from .env file
        load_dotenv()
        api_key = os.getenv("GOOGLE_API_KEY")

        if not api_key:
            raise ValueError("Error: 'GOOGLE_API_KEY' not set in .env file. Set it to use ToC extraction via Gemini LLM.")

        genai.configure(api_key=api_key)

        self.model_name = "models/gemini-2.5-flash"
        self.model = genai.GenerativeModel(self.model_name)
        self.pricing = self.MODEL_PRICING.get(self.model_name, self.MODEL_PRICING["default"])

        logger.info(f"LLM Agent (Gemini) initialized with model: {self.model_name}")

    def _execute_json_prompt(self, prompt: str, schema_dict: Dict[str, Any]) -> Tuple[Optional[dict], float]:
        """Vrac√≠ (v√Ωsledek_json, vypoƒçten√°_cena)."""
        try:
            config = genai.GenerationConfig(
                response_mime_type="application/json",
                response_schema=schema_dict 
            )
            response = self.model.generate_content(prompt, generation_config=config)
            
            cost = 0.0
            if response.usage_metadata:
                usage = response.usage_metadata
                in_tokens = usage.prompt_token_count
                out_tokens = usage.candidates_token_count
                
                cost = ((in_tokens / 1_000_000) * self.pricing["input"]) + \
                       ((out_tokens / 1_000_000) * self.pricing["output"])

                logger.debug(f"LLM usage: Input {in_tokens} tokens, Output {out_tokens} tokens, Cost: ${cost:.6f}")

            return json.loads(response.text), cost

        except json.JSONDecodeError as e:
            logger.error(f"LLM returned invalid JSON: {e}", exc_info=True)
            raise RuntimeError("ToC extraction failed: LLM returned malformed response") from e
        except Exception as e:
            logger.error(f"Unexpected error in LLM execution: {e}", exc_info=True)
            raise RuntimeError(f"ToC extraction failed unexpectedly: {str(e)}") from e

    def find_first_chapter_page(self, toc_page_text: str) -> Tuple[Optional[int], float]:
        """F√°ze 1: Nyn√≠ vrac√≠ (ƒç√≠slo_str√°nky, cena)."""
        prompt = f"""
        Analyzuj n√°sleduj√≠c√≠ text prvn√≠ str√°nky obsahu.
        Identifikuj prvn√≠ z√°znam, kter√Ω se v obsahu nach√°z√≠. Ten oznaƒçuje zaƒç√°tek prvn√≠ sekce skuteƒçn√©ho obsahu dokumentu. Vra≈• ƒç√≠slo str√°nky (1-based), kde tato sekce zaƒç√≠n√°.
        Nez√°le≈æ√≠ na tom, jakou m√° tato sekce √∫rove≈à (kapitola, podkapitola atd.). ≈òiƒè se t√≠m, ≈æe by to mƒõl b√Ωt prvn√≠ z√°znam. Ignoruj polo≈æku jako 'Obsah', 'Contents'nebo 'Table of Contents'. 
        Vra≈• POUZE JSON objekt podle sch√©matu.

        TEXT PRVN√ç STR√ÅNKY OBSAHU:
        {toc_page_text[:4000]} 
        """ 
        
        result, cost = self._execute_json_prompt(prompt, FIRST_CHAPTER_SCHEMA_DICT)

        if result and 'first_chapter_page' in result:
            return int(result['first_chapter_page']), cost

        print("‚ö†Ô∏è LLM (F√°ze 1) selhal p≈ôi hled√°n√≠ 'first_chapter_page'.")
        return None, cost

    def extract_full_structure(self, full_toc_text: str) -> Tuple[List[HeadingData], float]:
        """F√°ze 2: Nyn√≠ vrac√≠ (seznam_nadpis≈Ø, cena)."""
        prompt = f"""
        Analyzuj kompletn√≠ text obsahu (TOC) dokumentu. 
        Ignoruj polo≈æky jako 'Obsah' nebo 'Seznam obr√°zk≈Ø'.
        Extrahuj kompletn√≠ hierarchickou strukturu (kapitoly, sekce, podsekce).
        Odvoƒè √∫rove≈à (level) z ƒç√≠slov√°n√≠ (nap≈ô. 1.1 = level 2, A. = level 2) a odsazen√≠.
        Vra≈• POUZE JSON objekt podle sch√©matu.

        KOMPLETN√ç TEXT OBSAHU:
        {full_toc_text}
        """
        
        result, cost = self._execute_json_prompt(prompt, FULL_STRUCTURE_SCHEMA_DICT)
        headings_list: List[HeadingData] = []
        
        if result and 'headings' in result:
            for item in result['headings']:
                headings_list.append(
                    (item['title'], item['level'], item['page_number'])
                )
        else:
             print("‚ö†Ô∏è LLM (F√°ze 2) selhal p≈ôi extrakci 'headings'.")

        return headings_list, cost
# ==============================================================================
# 2. KONKR√âTN√ç PARSERY
# ==============================================================================

class PDFParser(BaseDocumentParser):
    
    def __init__(self, file_path: str, max_toc_pages: int = 10):
        super().__init__(file_path)
        # max_toc_pages nyn√≠ slou≈æ√≠ jako limit pro hled√°n√≠ *zaƒç√°tku* TOC
        self.max_toc_pages_search: int = max_toc_pages
        try:
            self.llm_agent = LLMAgent()
        except ValueError as e:
            print(f"üõë {e}")
            self.llm_agent = None

    def get_document_type(self) -> str:
        return "PDF"
        
    def parse_document(self) -> Dict[str, Any]:
        """Open PDF document and return metadata."""
        try:
            doc = fitz.open(self.file_path)
            return {"doc_object": doc, "page_count": doc.page_count}
        except fitz.FileDataError as e:
            logger.error(f"PDF file is corrupted or malformed: {self.file_path}", exc_info=True)
            raise RuntimeError(f"Cannot open PDF: file is corrupted or password-protected") from e
        except PermissionError as e:
            logger.error(f"Permission denied reading PDF: {self.file_path}", exc_info=True)
            raise RuntimeError(f"Cannot open PDF: permission denied") from e
        except Exception as e:
            logger.error(f"Unexpected error opening PDF {self.file_path}: {e}", exc_info=True)
            raise RuntimeError(f"Failed to open PDF: {str(e)}") from e

    def find_toc_scope(self) -> Tuple[Optional[int], Optional[int], Optional[str], float, str]:
        """
        F√ÅZE 1: Najde poƒç√°teƒçn√≠ a koncov√Ω index str√°nky obsahu.
        Vrac√≠ (start_index, end_index, text_prvn√≠_str√°nky, cena, STATUS)
        """
        print("--- PDFParser: Spou≈°t√≠m F√°zi 1 (Hled√°n√≠ Rozsahu TOC) ---")
        total_cost = 0.0
        data = self.parse_document()
        doc: fitz.Document = data.get("doc_object")
        
        if not doc:
            return None, None, None, 0.0, "ERROR_DOC_OPEN"
        if not self.llm_agent:
            doc.close()
            return None, None, None, 0.0, "ERROR_AGENT_INIT"

        # Tier 1 (Outline) m√° p≈ôednost
        if doc.get_toc():
            print("INFO: Dokument m√° Tier 1 Outline, F√°ze 1 se p≈ôeskakuje.")
            doc.close()
            # Vrac√≠me nov√Ω stavov√Ω k√≥d
            return None, None, None, 0.0, "TIER_1_SUCCESS" 

        # F√°ze 1A: Detekce *zaƒç√°tku* TOC (Heuristika)
        toc_start_page_index = -1
        first_page_text = ""
        for i in range(min(doc.page_count, self.max_toc_pages_search)):
            text = doc[i].get_text("text")
            if re.search(r'(table of contents|contents|obsah|seznam|content)', text[:500], re.IGNORECASE):
                toc_start_page_index = i
                first_page_text = text
                break
        
        if toc_start_page_index == -1:
            print("‚ö†Ô∏è F√°ze 1: Zaƒç√°tek TOC nenalezen (Tier 2 Heuristika selhala).")
            doc.close()
            # Vrac√≠me nov√Ω stavov√Ω k√≥d
            return None, None, None, 0.0, "TIER_2_FAILURE"

        # F√°ze 1B: Detekce *konce* TOC (Vol√°n√≠ LLM ƒç. 1)
        print("ü§ñ LLM Agent (F√°ze 1): Hled√°m konec TOC...")
        first_chapter_page, cost1 = self.llm_agent.find_first_chapter_page(first_page_text)
        total_cost += cost1
        
        toc_end_page_index: int
        if not first_chapter_page:
            print("‚ö†Ô∏è LLM (F√°ze 1) selhal. Pou≈æ√≠v√°m fallback (pouze 1 str√°nka TOC).")
            toc_end_page_index = toc_start_page_index
        else:
            toc_end_page_index = first_chapter_page - 2 # 1-based stranu na 0-based index
            if toc_end_page_index < toc_start_page_index:
                toc_end_page_index = toc_start_page_index
        
        doc.close()
        print(f"‚úÖ F√°ze 1: Rozsah TOC definov√°n: Strany {toc_start_page_index + 1} a≈æ {toc_end_page_index + 1}.")
        # Vrac√≠me nov√Ω stavov√Ω k√≥d
        return toc_start_page_index, toc_end_page_index, first_page_text, total_cost, "TIER_2_SUCCESS"

    def extract_structure_from_scope(self, toc_start_page_index: int, toc_end_page_index: int) -> Tuple[List[HeadingData], Optional[str], float]:
        """
        F√ÅZE 2: Extrahuje kompletn√≠ strukturu z dan√©ho rozsahu str√°nek.
        Vrac√≠ (nadpisy, surov√Ω_text, cena).
        """
        print("--- PDFParser: Spou≈°t√≠m F√°zi 2 (Extrakce Struktury) ---")
        data = self.parse_document()
        doc: fitz.Document = data.get("doc_object")
        if not doc or not self.llm_agent:
            if doc: doc.close()
            return [], None, 0.0
            
        # F√°ze 2A: Extrakce kompletn√≠ho textu TOC
        full_toc_text = ""
        for i in range(toc_start_page_index, min(toc_end_page_index + 1, doc.page_count)):
            full_toc_text += doc[i].get_text("text") + "\n--- Page Break ---\n"
        
        doc.close()

        # F√°ze 2B: Extrakce struktury (Vol√°n√≠ LLM ƒç. 2)
        print("ü§ñ LLM Agent (F√°ze 2): Extrahuje kompletn√≠ strukturu...")
        structured_headings, cost2 = self.llm_agent.extract_full_structure(full_toc_text)
             
        return structured_headings, full_toc_text, cost2

    def extract_structured_headings(self) -> Tuple[List[HeadingData], Optional[str], float]:
        """
        Orchestraƒçn√≠ metoda (F√°ze 0), kter√° vol√° F1 i F2.
        Vrac√≠ (nadpisy, surov√Ω_text, celkov√°_cena)
        """
        data = self.parse_document()
        doc: fitz.Document = data.get("doc_object")
        if not doc: 
            return [], None, 0.0

        # TIER 1 (Outline) m√° st√°le p≈ôednost
        outline = doc.get_toc()
        if outline:
            print("‚úÖ Struktura Extrahov√°na z PDF Outline/Bookmarks (Tier 1).")
            headings = [(title, level, page + 1) for level, title, page in outline]
            doc.close()
            return headings, None, 0.0 # Vrac√≠me (data, text, cena)

        # Tier 1 selhal, vol√°me F√°zi 1
        doc.close() # Zav≈ôeme dokument, F√°ze 1 si ho otev≈ôe znovu
        toc_start, toc_end, _, cost1, status = self.find_toc_scope()
        
        # Kontrolujeme explicitn√≠ √∫spƒõch F√°ze 1
        if status != "TIER_2_SUCCESS":
            # Toto nyn√≠ pokryje TIER_1_SUCCESS (kter√Ω by se zde nemƒõl st√°t)
            # a hlavnƒõ TIER_2_FAILURE
            return [], None, cost1 

        # Vol√°me F√°zi 2
        headings, ocr_text, cost2 = self.extract_structure_from_scope(toc_start, toc_end)
        
        total_cost = cost1 + cost2
        return headings, ocr_text, total_cost
# ==============================================================================
# 3. ≈ò√çDIC√ç MODUL A TESTOVAC√ç R√ÅMEC
# ==============================================================================

# Mapov√°n√≠ pro ≈ô√≠dic√≠ modul
PARSER_MAPPING: Dict[str, Type[BaseDocumentParser]] = {
    '.pdf': PDFParser
    # .tex a .txt by zde byly, pokud by byly implementov√°ny
}

class DocumentHierarchyTool:
    """
    Hlavn√≠ ≈ô√≠dic√≠ t≈ô√≠da (Facade/Factory). Nyn√≠ spr√°vnƒõ propaguje n√°klady.
    """
    
    def __init__(self):
        self.builder = HierarchyBuilder()
        # P≈ôedpoklad: PARSER_MAPPING je definov√°n glob√°lnƒõ nebo jako atribut
        self.PARSER_MAPPING = PARSER_MAPPING 

    def get_parser(self, file_path: str) -> Optional[BaseDocumentParser]:
        ext = os.path.splitext(file_path)[-1].lower()
        ParserClass = self.PARSER_MAPPING.get(ext)
        if ParserClass:
            return ParserClass(file_path)
        return None

    def process_document(self, file_path: str) -> Tuple[Optional['HierarchyNode'], Optional[str], float]:
        """
        Spou≈°t√≠ proces a vrac√≠ strom, surov√Ω OCR text a CELKOVOU CENU.
        """
        if not os.path.exists(file_path):
            return None, None, 0.0
            
        parser = self.get_parser(file_path)
        if not parser:
            return None, None, 0.0

        # Rozbal√≠me 3 hodnoty: nadpisy, OCR text, n√°klady na LLM
        structured_headings, ocr_text, total_cost = parser.extract_structured_headings()

        if not structured_headings:
            return None, ocr_text, total_cost

        document_tree = self.builder.build_tree(structured_headings)

        return document_tree, ocr_text, total_cost

# --- Pomocn√° funkce pro vizualizaci (pro kontext, mƒõla by b√Ωt definov√°na glob√°lnƒõ/jinde) ---
def visualize_tree_to_string(node: 'HierarchyNode', prefix: str = "", is_last: bool = True) -> List[str]:
    """Rekurzivn√≠ funkce, kter√° vizualizuje strom do seznamu ≈ôetƒõzc≈Ø."""
    lines = []
    if node.level != 0: # Nezobrazujeme virtu√°ln√≠ ko≈ôen
        line = prefix + ("‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ ") + \
               f"[{node.level}] {node.title[:80]} (Strana {node.page_number})"
        lines.append(line)
    
    child_count = len(node.children)
    next_prefix = prefix + ("    " if is_last else "‚îÇ   ")
    
    for i, child in enumerate(node.children):
        is_last_child = i == child_count - 1
        lines.extend(visualize_tree_to_string(child, next_prefix, is_last_child))
            
    return lines

# --- Opraven√° T≈ô√≠da DocumentTestRunner ---

class DocumentTestRunner:
    
    def __init__(self, test_dir_path: str, output_dir_path: str = "test_results"):
        """
        Inicializuje Runner cestami a p≈ôiprav√≠ v√Ωstupn√≠ slo≈æku.
        """
        self.test_dir = test_dir_path
        self.output_dir = output_dir_path
        self.tool = DocumentHierarchyTool() 
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"‚úÖ TestRunner inicializov√°n. V√Ωstupy budou ulo≈æeny do: {self.output_dir}")

    def run_tests(self, phase: str = "full"):
        """
        Spou≈°t√≠ testov√°n√≠ v r≈Øzn√Ωch f√°z√≠ch.
        
        Args:
            phase (str): M√≥d testov√°n√≠: 'full', 'scope', 'structure'.
        """
        print(f"\n===== ZAH√ÅJEN√ç TESTOVAC√çHO BƒöHU (F√ÅZE: {phase.upper()}) =====")
        
        if not os.path.isdir(self.test_dir):
            print(f"üõë Chyba: Testovac√≠ slo≈æka nenalezena na cestƒõ: {self.test_dir}")
            return
        
        supported_extensions = list(self.tool.PARSER_MAPPING.keys())

        for filename in sorted(os.listdir(self.test_dir)):
            
            file_path = os.path.join(self.test_dir, filename)

            if not os.path.isfile(file_path):
                continue # P≈ôeskoƒç√≠me slo≈æky

            ext = os.path.splitext(filename)[-1].lower()
            
            if ext not in supported_extensions:
                print(f"\n--- SKIPPING {filename}: Nepodporovan√Ω typ ({ext}) ---")
                continue
            
            # --- Z√çSK√ÅN√ç PARSERU ---
            parser = self.tool.get_parser(file_path) 
            
            if not parser:
                print(f"--- SKIPPING {filename}: Nebyl nalezen parser ---")
                continue
                
            # Dvouf√°zov√© testov√°n√≠ je relevantn√≠ pouze pro PDFParser
            if not isinstance(parser, PDFParser) and phase != "full":
                print(f"--- SKIPPING {filename}: F√°zov√© testov√°n√≠ je jen pro PDFParser ---")
                continue

            print(f"\n--- SPOU≈†T√çM TEST: {filename} (M√≥d: {phase}) ---")

            # --- V√ùBƒöR F√ÅZE ---
            
            if phase == "scope":
                # F√ÅZE 1: POUZE HLED√ÅN√ç ROZSAHU
                output_path = os.path.join(self.output_dir, f"{filename}_PHASE1_SCOPE.txt")
                
                # Rozbal√≠me 5 hodnot vƒçetnƒõ 'status'
                toc_start, toc_end, first_page_text, cost1, status = parser.find_toc_scope()
                
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(f"V√ùSLEDEK F√ÅZE 1 (HLED√ÅN√ç ROZSAHU) PRO: {filename}\n")
                    f.write(f"ODHADOVAN√Å CENA F√ÅZE 1: ${cost1:.8f} USD\n")
                    f.write("="*60 + "\n")

                    # --- NOV√Å LOGIKA PRO JASN√ù V√ùSTUP ---
                    if status == "TIER_1_SUCCESS":
                        f.write("STATUS: √öSPƒöCH (TIER 1 - PDF OUTLINE)\n")
                        f.write("LLM F√°ze 1 nebyla spu≈°tƒõna, proto≈æe dokument obsahuje vestavƒõn√© PDF Z√°lo≈æky (Outline).\n")
                    
                    elif status == "TIER_2_FAILURE":
                        f.write("STATUS: SELH√ÅN√ç (TIER 2 - DETEKCE)\n")
                        f.write("LLM F√°ze 1 nebyla spu≈°tƒõna, proto≈æe heuristika nena≈°la titulek 'Obsah' na prvn√≠ch stran√°ch.\n")
                    
                    elif status == "TIER_2_SUCCESS":
                        f.write("STATUS: √öSPƒöCH (LLM F√ÅZE 1)\n")
                        f.write(f"Rozsah nalezen (0-based index): Strana {toc_start} a≈æ {toc_end}\n")
                        f.write("\n--- Text prvn√≠ strany (pou≈æit√Ω pro LLM F1) ---\n")
                        f.write(first_page_text if first_page_text else "N/A")
                    
                    else: # nap≈ô. ERROR_PARSER_INIT
                        f.write(f"STATUS: CHYBA ({status})\n")
                        f.write("Do≈°lo k chybƒõ p≈ôi inicializaci parseru nebo agenta.\n")
                    # --- KONEC NOV√â LOGIKY ---
                        
                print(f"‚úÖ F√°ze 1: V√Ωsledek ulo≈æen do {output_path}")

            elif phase == "structure":
                # F√ÅZE 2: POUZE ANAL√ùZA STRUKTURY
                output_path = os.path.join(self.output_dir, f"{filename}_PHASE2_STRUCTURE.txt")
                
                print("   (Spou≈°t√≠m F1 pro z√≠sk√°n√≠ rozsahu...)")
                toc_start, toc_end, _, cost1, status = parser.find_toc_scope()
                
                if status != "TIER_2_SUCCESS":
                    print(f"   F1 selhala (Status: {status}), F2 nelze spustit.")
                    with open(output_path, 'w', encoding='utf-8') as f:
                        f.write(f"F√ÅZE 2 P≈òESKOƒåENA: F√°ze 1 nenalezla rozsah TOC (Status: {status}).")
                    continue
                    
                document_tree, ocr_source_text, cost2 = parser.extract_structure_from_scope(toc_start, toc_end)
                total_cost = cost1 + cost2
                self._save_results(output_path, filename, "F√ÅZE 2 (STRUKTURA)", document_tree, ocr_source_text, total_cost)
            
            else: # "full" (default)
                # PLN√ù BƒöH (p≈ôes DocumentHierarchyTool)
                output_path = os.path.join(self.output_dir, f"{filename}_FULL_RUN.txt")
                
                # Zde mus√≠me aktualizovat DocumentHierarchyTool, aby vracel n√°klady
                # Prozat√≠m p≈ôedpokl√°d√°me, ≈æe self.tool.process_document() vrac√≠ 3 hodnoty
                document_tree, ocr_source_text, total_cost = self.tool.process_document(file_path) 
                self._save_results(output_path, filename, "PLN√ù BƒöH (F1+F2)", document_tree, ocr_source_text, total_cost)

    def _save_results(self, output_path: str, filename: str, run_type: str, 
                      document_tree: Optional['HierarchyNode'], 
                      ocr_source_text: Optional[str], 
                      total_cost: float): # P≈ôid√°n parametr total_cost
        """Pomocn√° metoda pro ukl√°d√°n√≠ v√Ωsledk≈Ø."""
        
        if document_tree:
            tree_lines = visualize_tree_to_string(document_tree, is_last=True)
            header = [
                "*" * 60,
                f"V√ùSLEDEK BƒöHU ({run_type}) PRO: {filename}",
                f"ODHADOVAN√Å CELKOV√Å CENA: ${total_cost:.8f} USD", # Zobrazen√≠ ceny
                "*" * 60,
            ]
            
            if ocr_source_text:
                ocr_section = [
                    "\n" + "#" * 70,
                    "# SUROV√ù TEXT P≈òEDAN√ù LLM (F√ÅZE 2)",
                    "#" * 70,
                    ocr_source_text,
                    "\n" + "-" * 70,
                    "V√ùSLEDEK PARSOV√ÅN√ç STRUKTURY:",
                ]
                header.extend(ocr_section)
            
            header.extend([f"KO≈òEN STROMU: {document_tree.title}", "-" * 60])
            final_output = header + tree_lines
            
            try:
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write('\n'.join(final_output))
                print(f"‚úÖ {run_type}: V√Ωsledek ulo≈æen do {output_path}")
            except Exception as e:
                print(f"‚ùå Chyba p≈ôi ukl√°d√°n√≠ souboru {output_path}: {e}")

        else:
            log_content = f"üõë Zpracov√°n√≠ ({run_type}) pro {filename} selhalo.\n"
            log_content += f"Celkov√© n√°klady (p≈ôed selh√°n√≠m): ${total_cost:.8f} USD\n"
            if ocr_source_text:
                log_content += "\n--- SUROV√ù TEXT P≈òEDAN√ù LLM ---\n" + ocr_source_text
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(log_content)
            print(f"üõë {run_type}: Zpracov√°n√≠ selhalo, ulo≈æen log do: {output_path}")


if __name__ == "__main__":
    """
    Example usage - customize paths for your environment.

    Usage:
        python src/ToC_retrieval.py [test_dir] [output_dir] [phase]

    Args:
        test_dir: Directory containing PDF files to test (default: "test_data/")
        output_dir: Directory for output files (default: "test_results/")
        phase: Test phase - "full", "scope", or "structure" (default: "full")
    """
    import sys

    # Parse command-line arguments or use defaults
    test_path = sys.argv[1] if len(sys.argv) > 1 else "test_data/"
    output_path = sys.argv[2] if len(sys.argv) > 2 else "test_results/"
    phase = sys.argv[3] if len(sys.argv) > 3 else "full"

    # Run tests
    testing = DocumentTestRunner(test_dir_path=test_path, output_dir_path=output_path)
    testing.run_tests(phase=phase)
